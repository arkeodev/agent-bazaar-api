{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Async Job Queues with ARQ in FastAPI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we'll delve into how to implement asynchronous job queues in FastAPI using **ARQ** (Asynchronous Redis Queue). We'll start by understanding what ARQ is, explore its key classes and methods, and then build a sample application step by step. By the end of this tutorial, you'll have a solid grasp of how to leverage ARQ to run background tasks efficiently in your FastAPI applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Introduction to ARQ](#1-introduction-to-arq)\n",
    "2. [Understanding ARQ's Key Components](#2-understanding-arqs-key-components)\n",
    "3. [Prerequisites](#3-prerequisites)\n",
    "4. [Setting Up the Environment](#4-setting-up-the-environment)\n",
    "5. [Installing Dependencies](#5-installing-dependencies)\n",
    "6. [Configuring Redis](#6-configuring-redis)\n",
    "7. [Creating Background Tasks](#7-creating-background-tasks)\n",
    "8. [Configuring the ARQ Worker](#8-configuring-the-arq-worker)\n",
    "9. [Integrating ARQ with FastAPI](#9-integrating-arq-with-fastapi)\n",
    "10. [Testing the Background Tasks](#10-testing-the-background-tasks)\n",
    "11. [Advanced Usage](#11-advanced-usage)\n",
    "12. [Conclusion](#12-conclusion)\n",
    "13. [References](#13-references)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction to ARQ\n",
    "\n",
    "**ARQ (Asynchronous Redis Queue)** is a high-performance, asyncio-compatible job queue for Python. It allows you to run time-consuming tasks in the background, enabling your FastAPI application to remain responsive while handling long-running operations.\n",
    "\n",
    "### Why Use ARQ?\n",
    "\n",
    "- **Asynchronous Execution**: Leverages Python's `asyncio` for non-blocking operations.\n",
    "- **Redis Backend**: Uses Redis for task queuing and result storage, ensuring fast and reliable communication.\n",
    "- **Flexible Scheduling**: Supports immediate execution, delayed tasks, and periodic jobs using cron syntax.\n",
    "- **Ease of Integration**: Designed to work seamlessly with FastAPI and other asyncio-based frameworks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Understanding ARQ's Key Components\n",
    "\n",
    "Before we dive into the implementation, let's familiarize ourselves with the key components of ARQ.\n",
    "\n",
    "### 2.1. `arq.connections`\n",
    "\n",
    "- **`ArqRedis`**: The main class used to interact with Redis. It provides methods to enqueue jobs, check job status, and retrieve results.\n",
    "- **`create_pool`**: An async function that creates a connection pool to Redis, returning an `ArqRedis` instance.\n",
    "- **`RedisSettings`**: A configuration class for Redis connection parameters (host, port, password, etc.).\n",
    "\n",
    "### 2.2. Worker Settings\n",
    "\n",
    "- **`WorkerSettings`**: A class where you define the configuration for the ARQ worker. Key attributes include:\n",
    "  - `functions`: A list of task functions that the worker can execute.\n",
    "  - `redis_settings`: An instance of `RedisSettings` specifying how to connect to Redis.\n",
    "  - `on_startup` and `on_shutdown`: Async functions called when the worker starts up or shuts down.\n",
    "  - `cron_jobs`: A list of `cron` definitions for scheduling periodic tasks.\n",
    "\n",
    "### 2.3. Job Functions\n",
    "\n",
    "- **Task Functions**: Asynchronous functions that define the tasks you want to run in the background. These functions must be async and are executed by the ARQ worker.\n",
    "- **Context (`ctx`)**: An object passed to each task function, allowing access to shared resources like database connections or sessions.\n",
    "\n",
    "### 2.4. Job Management\n",
    "\n",
    "- **Enqueuing Jobs**: Using `ArqRedis.enqueue_job()` to schedule tasks for execution.\n",
    "- **Job Status and Results**: Methods to check the status (`queued`, `in_progress`, `complete`, `failed`) and retrieve results of jobs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prerequisites\n",
    "\n",
    "Ensure you have the following installed:\n",
    "\n",
    "- **Python 3.8+**: ARQ requires Python 3.8 or higher.\n",
    "- **Redis Server**: ARQ uses Redis as the backend. You can install it locally or run it via Docker.\n",
    "- **Basic Knowledge**: Familiarity with FastAPI, asynchronous programming (`async`/`await`), and Redis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Setting Up the Environment\n",
    "\n",
    "Let's start by setting up a virtual environment for our project.\n",
    "\n",
    "```bash\n",
    "# Create a new directory for the project\n",
    "mkdir fastapi-arq-demo\n",
    "cd fastapi-arq-demo\n",
    "\n",
    "# Set up a virtual environment\n",
    "python -m venv venv\n",
    "source venv/bin/activate  # On Windows, use: venv\\Scripts\\activate\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Installing Dependencies\n",
    "\n",
    "Install the required packages using `pip`.\n",
    "\n",
    "```bash\n",
    "pip install fastapi uvicorn arq redis[async]\n",
    "```\n",
    "\n",
    "- **`fastapi`**: Web framework for building APIs.\n",
    "- **`uvicorn`**: ASGI server for running FastAPI applications.\n",
    "- **`arq`**: Asynchronous job queue library.\n",
    "- **`redis[async]`**: Redis client with async support."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Configuring Redis\n",
    "\n",
    "Ensure you have a Redis server running. You can install Redis locally or run it using Docker.\n",
    "\n",
    "### Using Docker\n",
    "\n",
    "```bash\n",
    "docker run -d -p 6379:6379 --name redis redis:alpine\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Creating Background Tasks\n",
    "\n",
    "We'll create a sample background task that simulates sending emails asynchronously.\n",
    "\n",
    "### Directory Structure\n",
    "\n",
    "```\n",
    "fastapi-arq-demo/\n",
    "├── app/\n",
    "│   ├── __init__.py\n",
    "│   ├── main.py\n",
    "│   └── worker.py\n",
    "└── requirements.txt\n",
    "```\n",
    "\n",
    "Create the `app` directory and necessary files.\n",
    "\n",
    "```bash\n",
    "mkdir app\n",
    "touch app/__init__.py app/main.py app/worker.py\n",
    "```\n",
    "\n",
    "### 7.1. Defining the Task Function\n",
    "\n",
    "**app/worker.py**\n",
    "\n",
    "```python\n",
    "import asyncio\n",
    "from arq import cron\n",
    "from arq.connections import RedisSettings\n",
    "from datetime import datetime\n",
    "\n",
    "async def send_email(ctx, recipient: str, subject: str, body: str):\n",
    "    \"\"\"Simulates sending an email asynchronously.\"\"\"\n",
    "    print(f\"[{datetime.now()}] Starting to send email to {recipient}\")\n",
    "    # Simulate a delay in sending email\n",
    "    await asyncio.sleep(3)\n",
    "    print(f\"[{datetime.now()}] Email sent to {recipient} with subject '{subject}'\")\n",
    "    return f\"Email to {recipient} sent successfully\"\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "- The `send_email` function simulates an email-sending operation with a delay.\n",
    "- The function accepts `recipient`, `subject`, and `body` as parameters.\n",
    "- We use `await asyncio.sleep(3)` to simulate a 3-second delay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Configuring the ARQ Worker\n",
    "\n",
    "Next, we'll set up the worker settings so that ARQ knows how to execute our tasks.\n",
    "\n",
    "### 8.1. Worker Settings\n",
    "\n",
    "**app/worker.py** (continued)\n",
    "\n",
    "```python\n",
    "class WorkerSettings:\n",
    "    # List of functions the worker can execute\n",
    "    functions = [send_email]\n",
    "    # Redis connection settings\n",
    "    redis_settings = RedisSettings(host='localhost', port=6379)\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "- **`functions`**: A list containing the task functions the worker will execute.\n",
    "- **`redis_settings`**: Specifies the Redis server connection details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Integrating ARQ with FastAPI\n",
    "\n",
    "We'll now create FastAPI endpoints to enqueue tasks and check their status.\n",
    "\n",
    "### 9.1. Setting Up the FastAPI Application\n",
    "\n",
    "**app/main.py**\n",
    "\n",
    "```python\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from arq.connections import create_pool, RedisSettings\n",
    "from app.worker import send_email\n",
    "import asyncio\n",
    "\n",
    "app = FastAPI()\n",
    "redis_pool = None\n",
    "\n",
    "@app.on_event(\"startup\")\n",
    "async def startup_event():\n",
    "    global redis_pool\n",
    "    redis_pool = await create_pool(RedisSettings(host='localhost', port=6379))\n",
    "\n",
    "@app.on_event(\"shutdown\")\n",
    "async def shutdown_event():\n",
    "    await redis_pool.close()\n",
    "\n",
    "@app.post(\"/send-email\")\n",
    "async def send_email_endpoint(recipient: str, subject: str, body: str):\n",
    "    if not recipient or not subject or not body:\n",
    "        raise HTTPException(status_code=400, detail=\"All parameters are required\")\n",
    "    job = await redis_pool.enqueue_job(\"send_email\", recipient, subject, body)\n",
    "    return {\"message\": \"Email queued\", \"job_id\": job.job_id}\n",
    "\n",
    "@app.get(\"/job-status/{job_id}\")\n",
    "async def job_status(job_id: str):\n",
    "    try:\n",
    "        job_result = await redis_pool.get_job_result(job_id)\n",
    "        if job_result is None:\n",
    "            status = \"pending\"\n",
    "        else:\n",
    "            status = \"complete\"\n",
    "        return {\"job_id\": job_id, \"status\": status, \"result\": job_result}\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=404, detail=str(e))\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "- **`redis_pool`**: A global variable to hold the Redis connection pool.\n",
    "- **Startup and Shutdown Events**: Initialize and close the Redis connection pool.\n",
    "- **`/send-email` Endpoint**: Accepts `recipient`, `subject`, and `body`, and enqueues the `send_email` task.\n",
    "- **`/job-status/{job_id}` Endpoint**: Checks the status of the job and retrieves the result if available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Testing the Background Tasks\n",
    "\n",
    "### 10.1. Running the ARQ Worker\n",
    "\n",
    "Start the ARQ worker in a terminal window.\n",
    "\n",
    "```bash\n",
    "arq app.worker.WorkerSettings\n",
    "```\n",
    "\n",
    "**Expected Output:**\n",
    "\n",
    "```\n",
    "Worker for 1 functions started\n",
    "```\n",
    "\n",
    "### 10.2. Running the FastAPI Application\n",
    "\n",
    "In another terminal, start the FastAPI app.\n",
    "\n",
    "```bash\n",
    "uvicorn app.main:app --reload\n",
    "```\n",
    "\n",
    "### 10.3. Sending a Test Email\n",
    "\n",
    "Use `curl`, `httpie`, or any API client to send a request.\n",
    "\n",
    "```bash\n",
    "curl -X POST \"http://localhost:8000/send-email\" \\\n",
    "     -H \"Content-Type: application/json\" \\\n",
    "     -d '{\"recipient\": \"user@example.com\", \"subject\": \"Test Email\", \"body\": \"Hello from ARQ!\"}'\n",
    "```\n",
    "\n",
    "**Response:**\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"message\": \"Email queued\",\n",
    "  \"job_id\": \"e4b5a9d2-6d3c-4b8b-9a2f-c0a2e1f27e3e\"\n",
    "}\n",
    "```\n",
    "\n",
    "### 10.4. Checking Job Status\n",
    "\n",
    "```bash\n",
    "curl \"http://localhost:8000/job-status/e4b5a9d2-6d3c-4b8b-9a2f-c0a2e1f27e3e\"\n",
    "```\n",
    "\n",
    "**Possible Responses:**\n",
    "\n",
    "- **Pending Job:**\n",
    "\n",
    "  ```json\n",
    "  {\n",
    "    \"job_id\": \"e4b5a9d2-6d3c-4b8b-9a2f-c0a2e1f27e3e\",\n",
    "    \"status\": \"pending\",\n",
    "    \"result\": null\n",
    "  }\n",
    "  ```\n",
    "\n",
    "- **Completed Job:**\n",
    "\n",
    "  ```json\n",
    "  {\n",
    "    \"job_id\": \"e4b5a9d2-6d3c-4b8b-9a2f-c0a2e1f27e3e\",\n",
    "    \"status\": \"complete\",\n",
    "    \"result\": \"Email to user@example.com sent successfully\"\n",
    "  }\n",
    "  ```\n",
    "\n",
    "### 10.5. Observing Worker Logs\n",
    "\n",
    "In the terminal running the ARQ worker, you should see logs similar to:\n",
    "\n",
    "```\n",
    "[2024-10-16 12:00:00] Starting to send email to user@example.com\n",
    "[2024-10-16 12:00:03] Email sent to user@example.com with subject 'Test Email'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Advanced Usage\n",
    "\n",
    "Let's explore some advanced features of ARQ, such as passing context, scheduling tasks, and handling retries.\n",
    "\n",
    "### 11.1. Passing Context to Tasks\n",
    "\n",
    "You might need to share resources like database connections across tasks.\n",
    "\n",
    "#### 11.1.1. Modifying Worker Settings\n",
    "\n",
    "**app/worker.py**\n",
    "\n",
    "```python\n",
    "from databases import Database\n",
    "\n",
    "async def startup(ctx):\n",
    "    ctx['db'] = Database('sqlite:///example.db')\n",
    "    await ctx['db'].connect()\n",
    "\n",
    "async def shutdown(ctx):\n",
    "    await ctx['db'].disconnect()\n",
    "\n",
    "class WorkerSettings:\n",
    "    functions = [send_email]\n",
    "    redis_settings = RedisSettings(host='localhost', port=6379)\n",
    "    on_startup = startup\n",
    "    on_shutdown = shutdown\n",
    "```\n",
    "\n",
    "#### 11.1.2. Accessing Context in Tasks\n",
    "\n",
    "```python\n",
    "async def send_email(ctx, recipient: str, subject: str, body: str):\n",
    "    db = ctx['db']\n",
    "    # Use `db` for database operations\n",
    "    ...\n",
    "```\n",
    "\n",
    "### 11.2. Scheduling Tasks\n",
    "\n",
    "You can schedule tasks to run at a specific time using the `defer_until` parameter.\n",
    "\n",
    "**app/main.py**\n",
    "\n",
    "```python\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "@app.post(\"/schedule-email\")\n",
    "async def schedule_email(recipient: str, subject: str, body: str, delay_seconds: int):\n",
    "    if not recipient or not subject or not body:\n",
    "        raise HTTPException(status_code=400, detail=\"All parameters are required\")\n",
    "    defer_time = datetime.utcnow() + timedelta(seconds=delay_seconds)\n",
    "    job = await redis_pool.enqueue_job(\n",
    "        \"send_email\",\n",
    "        recipient,\n",
    "        subject,\n",
    "        body,\n",
    "        defer_until=defer_time\n",
    "    )\n",
    "    return {\n",
    "        \"message\": f\"Email scheduled to be sent in {delay_seconds} seconds\",\n",
    "        \"job_id\": job.job_id\n",
    "    }\n",
    "```\n",
    "\n",
    "### 11.3. Periodic Tasks with Cron\n",
    "\n",
    "Define tasks that run periodically.\n",
    "\n",
    "**app/worker.py**\n",
    "\n",
    "```python\n",
    "async def periodic_cleanup(ctx):\n",
    "    print(f\"[{datetime.now()}] Performing periodic cleanup tasks\")\n",
    "    # Implement cleanup logic here\n",
    "\n",
    "class WorkerSettings:\n",
    "    functions = [send_email, periodic_cleanup]\n",
    "    redis_settings = RedisSettings(host='localhost', port=6379)\n",
    "    cron_jobs = [\n",
    "        cron(\n",
    "            periodic_cleanup,\n",
    "            minute=0  # Runs every hour at minute 0\n",
    "        ),\n",
    "    ]\n",
    "```\n",
    "\n",
    "### 11.4. Handling Task Retries\n",
    "\n",
    "You can configure how ARQ handles task retries in case of failures.\n",
    "\n",
    "**app/worker.py**\n",
    "\n",
    "```python\n",
    "class WorkerSettings:\n",
    "    ...\n",
    "    retry_jobs = True  # Enable retries\n",
    "    max_tries = 3      # Maximum number of retries\n",
    "    retry_delay = 5    # Delay between retries in seconds\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Conclusion\n",
    "\n",
    "In this tutorial, we've covered:\n",
    "\n",
    "- The fundamentals of ARQ and its key components.\n",
    "- How to set up ARQ with FastAPI to run background tasks.\n",
    "- Enqueuing tasks and checking their status.\n",
    "- Advanced features like passing context, scheduling tasks, periodic jobs, and handling retries.\n",
    "\n",
    "By integrating ARQ into your FastAPI applications, you can efficiently manage long-running tasks without blocking the main application thread, resulting in more responsive and scalable APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. References\n",
    "\n",
    "- [ARQ Documentation](https://arq-docs.helpmanual.io/)\n",
    "- [FastAPI Official Documentation](https://fastapi.tiangolo.com/)\n",
    "- [Redis Official Site](https://redis.io/)\n",
    "- [Asyncio Event Loop](https://docs.python.org/3/library/asyncio-eventloop.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastapi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
